{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c_Tz_eFfbdN",
    "outputId": "ace1d46b-9780-486b-9206-4a89493972cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics + Dependencies Installed!\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "#   YOLOv11 + BDD100K Colab Notebook\n",
    "# ================================\n",
    "\n",
    "# ================================\n",
    "# 1. Install Dependencies\n",
    "# ================================\n",
    "!pip install ultralytics --quiet\n",
    "!pip install tqdm jsonlines --quiet\n",
    "!pip install roboflow --quiet\n",
    "\n",
    "print(\"Ultralytics + Dependencies Installed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7cEBXU0giTR",
    "outputId": "d224ff1e-bfcb-4cb4-c250-580b581f3572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Dataset root: /content/drive/MyDrive/BDD100K_YOLO\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 2. Mount Google Drive\n",
    "# ================================\n",
    "\"\"\"\n",
    "import os\n",
    "ROOT = \"./BDD100K_YOLO\"\n",
    "os.makedirs(ROOT, exist_ok=True)\n",
    "\"\"\"\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "ROOT = \"/content/drive/MyDrive/BDD100K_YOLO\"\n",
    "os.makedirs(ROOT, exist_ok=True)\n",
    "\n",
    "print(\"Dataset root:\", ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a0EfLzTg9rI",
    "outputId": "77bb41bc-eabe-4724-fe03-c57424176a44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-08 18:55:50--  http://128.32.162.150/bdd100k/bdd100k_images_100k.zip\n",
      "Connecting to 128.32.162.150:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5669071832 (5.3G) [application/zip]\n",
      "Saving to: ‚Äò/content/drive/MyDrive/BDD100K_YOLO/bdd100k_images.zip‚Äô\n",
      "\n",
      "/content/drive/MyDr 100%[===================>]   5.28G  11.2MB/s    in 8m 41s  \n",
      "\n",
      "2025-12-08 19:04:31 (10.4 MB/s) - ‚Äò/content/drive/MyDrive/BDD100K_YOLO/bdd100k_images.zip‚Äô saved [5669071832/5669071832]\n",
      "\n",
      "--2025-12-08 19:04:31--  http://128.32.162.150/bdd100k/bdd100k_labels.zip\n",
      "Connecting to 128.32.162.150:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 189638612 (181M) [application/zip]\n",
      "Saving to: ‚Äò/content/drive/MyDrive/BDD100K_YOLO/bdd100k_labels.zip‚Äô\n",
      "\n",
      "/content/drive/MyDr 100%[===================>] 180.85M  11.2MB/s    in 16s     \n",
      "\n",
      "2025-12-08 19:04:47 (11.6 MB/s) - ‚Äò/content/drive/MyDrive/BDD100K_YOLO/bdd100k_labels.zip‚Äô saved [189638612/189638612]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 3. Download BDD100K Dataset (Detection labels only)\n",
    "# ================================\n",
    "# Official Downloads:\n",
    "# Images: https://bdd-data.berkeley.edu/\n",
    "# Labels: https://bdd-data.berkeley.edu/\n",
    "\n",
    "!wget http://128.32.162.150/bdd100k/bdd100k_images_100k.zip -O {ROOT}/bdd100k_images.zip\n",
    "!wget http://128.32.162.150/bdd100k/bdd100k_labels.zip -O {ROOT}/bdd100k_labels.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgCW2djXhp2G",
    "outputId": "8f60c2ed-dd28-4d38-dc78-34214db2b1e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting images ...\n",
      "replace /content/drive/MyDrive/BDD100K_YOLO/images_100k/100k/train/6a9b44bd-91e97262.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: Extracting labels ...\n",
      "replace /content/drive/MyDrive/BDD100K_YOLO/labels_100k/100k/train/6866acb3-cf17e759.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: Extraction Complete!\n"
     ]
    }
   ],
   "source": [
    "# Extract everything\n",
    "\n",
    "# Folder Structure After Extraction:\n",
    "# ROOT/bdd100k/images/100k/{train,val}\n",
    "# ROOT/bdd100k/labels/det_20/{train,val}.json\n",
    "\n",
    "print(\"Extracting images ...\")\n",
    "!unzip -q {ROOT}/bdd100k_images.zip -d {ROOT}/images_100k\n",
    "\n",
    "print(\"Extracting labels ...\")\n",
    "!unzip -q {ROOT}/bdd100k_labels.zip -d {ROOT}/labels_100k\n",
    "\n",
    "print(\"Extraction Complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "J2Hpigy4K5Oe",
    "outputId": "3f797541-eda6-4daa-eef4-d1aee7b65293"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nimport os\\nimport json\\n\\nclasses = {\\n    \"person\": 0, \"rider\": 1, \"car\": 2, \"bus\": 3, \"truck\": 4,\\n    \"bike\": 5, \"motorcycle\": 6, \"traffic light\": 7,\\n    \"traffic sign\": 8, \"train\": 9\\n}\\njson_path = f\"/content/BDD100K_YOLO/labels/train/0000f77c-6257be58.json\"\\nwith open(json_path, \\'r\\') as jf:\\n  ann = json.load(jf)\\n  #shutil.copy(img_path, f\"{out_img_dir}/{img_name}\")\\n\\n# Height/width fallback\\n  h = ann.get(\"height\", 720)\\n  w = ann.get(\"width\", 1280)\\n\\n# Open output label file\\n  out_lbl_path = f\"/content/BDD100K_YOLO/0000f77c-6257be58.txt\"\\n  with open(out_lbl_path, \"w\") as out_f:\\n\\n    frame_objects = ann.get(\"frames\", [{}])[0].get(\"objects\", [])\\n\\n    # Loop through annotations\\n    for obj in frame_objects:\\n        cls_name = obj.get(\"category\")\\n\\n        # Skip unknown classes\\n        if cls_name not in classes:\\n            continue\\n\\n        # Bounding box\\n        box = obj.get(\"box2d\", None)\\n        if not box:\\n            continue\\n\\n        x1, y1, x2, y2 = box[\"x1\"], box[\"y1\"], box[\"x2\"], box[\"y2\"]\\n\\n        # Convert to YOLO format\\n        xc = (x1 + x2) / 2 / w\\n        yc = (y1 + y2) / 2 / h\\n        bw = (x2 - x1) / w\\n        bh = (y2 - y1) / h\\n\\n        out_f.write(f\"{classes[cls_name]} {xc} {yc} {bw} {bh}\\n\")\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debugging to check annotations are written in labels\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "\n",
    "classes = {\n",
    "    \"person\": 0, \"rider\": 1, \"car\": 2, \"bus\": 3, \"truck\": 4,\n",
    "    \"bike\": 5, \"motorcycle\": 6, \"traffic light\": 7,\n",
    "    \"traffic sign\": 8, \"train\": 9\n",
    "}\n",
    "json_path = f\"/content/BDD100K_YOLO/labels/train/0000f77c-6257be58.json\"\n",
    "with open(json_path, 'r') as jf:\n",
    "  ann = json.load(jf)\n",
    "  #shutil.copy(img_path, f\"{out_img_dir}/{img_name}\")\n",
    "\n",
    "# Height/width fallback\n",
    "  h = ann.get(\"height\", 720)\n",
    "  w = ann.get(\"width\", 1280)\n",
    "\n",
    "# Open output label file\n",
    "  out_lbl_path = f\"/content/BDD100K_YOLO/0000f77c-6257be58.txt\"\n",
    "  with open(out_lbl_path, \"w\") as out_f:\n",
    "\n",
    "    frame_objects = ann.get(\"frames\", [{}])[0].get(\"objects\", [])\n",
    "\n",
    "    # Loop through annotations\n",
    "    for obj in frame_objects:\n",
    "        cls_name = obj.get(\"category\")\n",
    "\n",
    "        # Skip unknown classes\n",
    "        if cls_name not in classes:\n",
    "            continue\n",
    "\n",
    "        # Bounding box\n",
    "        box = obj.get(\"box2d\", None)\n",
    "        if not box:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = box[\"x1\"], box[\"y1\"], box[\"x2\"], box[\"y2\"]\n",
    "\n",
    "        # Convert to YOLO format\n",
    "        xc = (x1 + x2) / 2 / w\n",
    "        yc = (y1 + y2) / 2 / h\n",
    "        bw = (x2 - x1) / w\n",
    "        bh = (y2 - y1) / h\n",
    "\n",
    "        out_f.write(f\"{classes[cls_name]} {xc} {yc} {bw} {bh}\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "lTJPew1XI1Dx",
    "outputId": "878a3d58-6751-48c9-e82b-b2c250878b00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Converting split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/70000 [00:00<58:28, 19.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-531556105.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mOUT_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/BDD100K_YOLO/dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mconvert_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJSON_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0mconvert_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJSON_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mconvert_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJSON_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-531556105.py\u001b[0m in \u001b[0;36mconvert_split\u001b[0;34m(split, IMG_DIR, JSON_DIR, OUT_DIR, classes)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Copy image to YOLO dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{out_img_dir}/{img_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Height/width fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                     \u001b[0;31m# macOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_split(split, IMG_DIR, JSON_DIR, OUT_DIR, classes):\n",
    "    \"\"\"\n",
    "    Convert per-image JSON annotations to YOLO TXT format.\n",
    "\n",
    "    Args:\n",
    "        split (str): \"train\", \"val\", or \"test\"\n",
    "        IMG_DIR (str): path to image directory containing JPGs\n",
    "        JSON_DIR (str): path to directory containing JSON files (one per image)\n",
    "        OUT_DIR (str): output directory root to save YOLO images/labels\n",
    "        classes (dict): category‚Üíindex mapping\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\nüîÑ Converting split: {split}\")\n",
    "\n",
    "    # Make output directories\n",
    "    out_img_dir = f\"{OUT_DIR}/{split}/images\"\n",
    "    out_lbl_dir = f\"{OUT_DIR}/{split}/labels\"\n",
    "    os.makedirs(out_img_dir, exist_ok=True)\n",
    "    os.makedirs(out_lbl_dir, exist_ok=True)\n",
    "\n",
    "    # Get all images for this split\n",
    "    image_list = sorted([f for f in os.listdir(f\"{IMG_DIR}/{split}\") if f.endswith('.jpg')])\n",
    "\n",
    "    for img_name in tqdm(image_list):\n",
    "\n",
    "        img_path = f\"{IMG_DIR}/{split}/{img_name}\"\n",
    "\n",
    "        # EXPECT JSON NAMED SAME AS IMAGE (e.g., 00001.jpg ‚Üí 00001.json)\n",
    "        json_name = img_name.replace(\".jpg\", \".json\")\n",
    "        json_path = f\"{JSON_DIR}/{split}/{json_name}\"\n",
    "\n",
    "        # Check if JSON exists\n",
    "        if not os.path.exists(json_path):\n",
    "            print(f\"‚ö†Ô∏è Missing annotation: {json_path} (skipping)\")\n",
    "            continue\n",
    "\n",
    "        # Load annotation JSON\n",
    "        with open(json_path, 'r') as jf:\n",
    "            ann = json.load(jf)\n",
    "\n",
    "        # Copy image to YOLO dataset\n",
    "        shutil.copy(img_path, f\"{out_img_dir}/{img_name}\")\n",
    "\n",
    "        # Height/width fallback\n",
    "        h = ann.get(\"height\", 720)\n",
    "        w = ann.get(\"width\", 1280)\n",
    "\n",
    "        # Open output label file\n",
    "        out_lbl_path = f\"{out_lbl_dir}/{img_name.replace('.jpg', '.txt')}\"\n",
    "        with open(out_lbl_path, \"w\") as out_f:\n",
    "\n",
    "            frame_objects = ann.get(\"frames\", [{}])[0].get(\"objects\", [])\n",
    "            # Loop through annotations\n",
    "            for obj in frame_objects:\n",
    "                cls_name = obj.get(\"category\")\n",
    "\n",
    "                # Skip unknown classes\n",
    "                if cls_name not in classes:\n",
    "                    continue\n",
    "\n",
    "                # Bounding box\n",
    "                box = obj.get(\"box2d\", None)\n",
    "                if not box:\n",
    "                    continue\n",
    "\n",
    "                x1, y1, x2, y2 = box[\"x1\"], box[\"y1\"], box[\"x2\"], box[\"y2\"]\n",
    "\n",
    "                # Convert to YOLO format\n",
    "                xc = (x1 + x2) / 2 / w\n",
    "                yc = (y1 + y2) / 2 / h\n",
    "                bw = (x2 - x1) / w\n",
    "                bh = (y2 - y1) / h\n",
    "\n",
    "                out_f.write(f\"{classes[cls_name]} {xc} {yc} {bw} {bh}\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Completed {split}\")\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Example Usage\n",
    "# ========================\n",
    "\n",
    "classes = {\n",
    "    \"person\": 0, \"rider\": 1, \"car\": 2, \"bus\": 3, \"truck\": 4,\n",
    "    \"bike\": 5, \"motorcycle\": 6, \"traffic light\": 7,\n",
    "    \"traffic sign\": 8, \"train\": 9\n",
    "}\n",
    "\n",
    "IMG_DIR = \"/content/drive/MyDrive/BDD100K_YOLO/images_100k/100k\"           # contains train/, val/, test/\n",
    "JSON_DIR = \"/content/drive/MyDrive/BDD100K_YOLO/labels_100k/100k\"     # contains train/, val/, test/\n",
    "OUT_DIR = \"/content/drive/MyDrive/BDD100K_YOLO/dataset\"\n",
    "\n",
    "convert_split(\"train\", IMG_DIR, JSON_DIR, OUT_DIR, classes)\n",
    "convert_split(\"val\", IMG_DIR, JSON_DIR, OUT_DIR, classes)\n",
    "convert_split(\"test\", IMG_DIR, JSON_DIR, OUT_DIR, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVoCABHriEG9"
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5. Create YAML File for Training\n",
    "# ================================\n",
    "yaml_path = f\"{ROOT}/bdd100k.yaml\"\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    f.write(f\"\"\"\n",
    "path: {ROOT}/dataset\n",
    "\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "names:\n",
    "  0: person\n",
    "  1: rider\n",
    "  2: car\n",
    "  3: bus\n",
    "  4: truck\n",
    "  5: bike\n",
    "  6: motorcycle\n",
    "  7: traffic light\n",
    "  8: traffic sign\n",
    "  9: train\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "print(\"bdd100k.yaml created!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVonUuuHjGZO"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os, json, shutil, zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===========================================\n",
    "# 1) Train YOLOv11 + Save Fine-Tuned Model\n",
    "# ===========================================\n",
    "\n",
    "save_dir = \"yolo11n_bdd100k\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    imgsz=640,\n",
    "    epochs=5,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    workers=2,\n",
    "    project=\"yolo11n_bdd100k\",        # save training logs here\n",
    "    name=\"train_run\",\n",
    "    save=True,\n",
    "    save_period=1            # save checkpoint every epoch\n",
    ")\n",
    "\n",
    "print(\"‚úî Training Completed!\")\n",
    "print(f\"‚úî Saved fine-tuned weights at: {save_dir}/train_run/weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fa5aABTijZg8"
   },
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 1) Save fine-tuned YOLO model\n",
    "# ===========================================\n",
    "\n",
    "model_path = \"/content/drive/MyDrive/BDD100K_YOLO/yolo_finetuned_bdd100k.pt\"\n",
    "model.save(model_path)\n",
    "print(f\"‚úî Fine-tuned model saved at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07fsNhRKf8eZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===========================================\n",
    "# 2) Generate Validation Performance Metrics\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\nüìä Generating Evaluation Metrics...\")\n",
    "\n",
    "metrics = model.val()    # runs validation & returns DetMetrics object\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# 3) Write metrics to a readable text file\n",
    "# ===========================================\n",
    "\n",
    "metrics_path = f\"{save_dir}/metrics_summary.txt\"\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "\n",
    "    f.write(\"===== YOLO Validation Metrics =====\\n\\n\")\n",
    "    f.write(f\"mAP@50:       {metrics.box.map50:.4f}\\n\")\n",
    "    f.write(f\"mAP@50-95:    {metrics.box.map:.4f}\\n\")\n",
    "    f.write(f\"Precision:    {metrics.box.mp:.4f}\\n\")\n",
    "    f.write(f\"Recall:       {metrics.box.mr:.4f}\\n\\n\")\n",
    "\n",
    "    # per-class AP if available\n",
    "    if hasattr(metrics.box, \"ap_class_index\"):\n",
    "        f.write(\"===== Per-Class AP =====\\n\")\n",
    "        for cls_idx, ap in zip(metrics.box.ap_class_index, metrics.box.ap):\n",
    "            f.write(f\"class {cls_idx}: AP = {ap:.4f}\\n\")\n",
    "\n",
    "print(\"‚úî Metrics written to:\", metrics_path)\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# 4) Print summary metrics to notebook output\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n===== VAL METRICS =====\")\n",
    "print(f\"mAP50:     {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95:  {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall:    {metrics.box.mr:.4f}\")\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# 5) Save Confusion Matrix Image\n",
    "# ===========================================\n",
    "\n",
    "if hasattr(metrics, \"confusion_matrix\") and metrics.confusion_matrix is not None:\n",
    "    metrics.confusion_matrix.plot(\n",
    "        normalize=True,\n",
    "        save_dir=save_dir\n",
    "    )\n",
    "    print(f\"‚úî Confusion matrix saved in {save_dir}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö† No confusion matrix found (possibly empty dataset or configuration).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpghusVaDfbU"
   },
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 3) Plot Train/Val Loss & Accuracy Curves\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\nüìâ Generating Training Curves...\")\n",
    "\n",
    "csv_path = f\"{save_dir}/train_run/results.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(df['epoch'], df['train/box_loss'], label='Train Box Loss')\n",
    "plt.plot(df['epoch'], df['train/cls_loss'], label='Train Cls Loss')\n",
    "plt.plot(df['epoch'], df['val/box_loss'], label='Val Box Loss')\n",
    "plt.plot(df['epoch'], df['val/cls_loss'], label='Val Cls Loss')\n",
    "\n",
    "plt.title(\"YOLOv11 Loss Curves\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{save_dir}/loss_curves.png\")\n",
    "plt.show()\n",
    "\n",
    "# Accuracy metrics plot (Precision, Recall, mAP)\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(df['epoch'], df['metrics/precision(B)'], label=\"Precision\")\n",
    "plt.plot(df['epoch'], df['metrics/recall(B)'], label=\"Recall\")\n",
    "plt.plot(df['epoch'], df['metrics/mAP50(B)'], label=\"mAP50\")\n",
    "plt.plot(df['epoch'], df['metrics/mAP50-95(B)'], label=\"mAP50-95\")\n",
    "\n",
    "plt.title(\"YOLOv11 Accuracy Metrics Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{save_dir}/metric_curves.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úî Training curves saved in:\", save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3v9efEUDsk7"
   },
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 4) Run Inference on Test Dataset\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\nüîç Running Inference on TEST Images...\")\n",
    "\n",
    "test_results_dir = \"/content/drive/MyDrive/BDD100K_YOLO/test_preds\"\n",
    "os.makedirs(test_results_dir, exist_ok=True)\n",
    "\n",
    "preds = model.predict(\n",
    "    source=f\"{ROOT}/dataset/test/images\",\n",
    "    imgsz=640,\n",
    "    save=True,\n",
    "    project=test_results_dir,\n",
    "    name=\"preds\",\n",
    "    conf=0.25\n",
    ")\n",
    "\n",
    "print(\"‚úî Inference Completed!\")\n",
    "print(\"‚úî Output saved at:\", test_results_dir + \"/preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zc1WWhB5Imjr"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: Display a few predictions\n",
    "import glob\n",
    "from IPython.display import Image\n",
    "\n",
    "pred_imgs = glob.glob(test_results_dir + \"/preds/*.jpg\")[:5]\n",
    "for img in pred_imgs:\n",
    "    display(Image(filename=img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "IMhkM8rfuQai",
    "outputId": "3008a0f1-3e28-4308-aff9-512354a04e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.235 üöÄ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolo11n_bdd100k/train_run/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 14, 8400) (5.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.78...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.2s, saved as '/content/yolo11n_bdd100k/train_run/weights/best.onnx' (10.1 MB)\n",
      "\n",
      "Export complete (1.4s)\n",
      "Results saved to \u001b[1m/content/yolo11n_bdd100k/train_run/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/content/yolo11n_bdd100k/train_run/weights/best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/content/yolo11n_bdd100k/train_run/weights/best.onnx imgsz=640 data=/content/drive/MyDrive/BDD100K_YOLO/bdd100k.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/yolo11n_bdd100k/train_run/weights/best.onnx'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export the model in ONNX format for inference\n",
    "\n",
    "model.export(\n",
    "    format=\"onnx\",\n",
    "    opset=12,          # ‚ú® REQUIRED for OpenCV\n",
    "    simplify=True,\n",
    "    dynamic=False       # recommended\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
