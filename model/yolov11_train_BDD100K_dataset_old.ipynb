{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c_Tz_eFfbdN",
    "outputId": "c55c6f17-48ea-4502-f351-b0b1b01048a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics + Dependencies Installed!\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "#   YOLOv11 + BDD100K Colab Notebook\n",
    "# ================================\n",
    "\n",
    "# ================================\n",
    "# 1. Install Dependencies\n",
    "# ================================\n",
    "!pip install ultralytics --quiet\n",
    "!pip install tqdm jsonlines --quiet\n",
    "!pip install roboflow --quiet\n",
    "\n",
    "print(\"Ultralytics + Dependencies Installed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m7cEBXU0giTR"
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. Mount Google Drive\n",
    "# ================================\n",
    "import os\n",
    "ROOT = \"./BDD100K_YOLO\"\n",
    "os.makedirs(ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a0EfLzTg9rI",
    "outputId": "98c4b4e0-3e52-4cf9-dc90-827a2370b503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 3. Download BDD100K Dataset (Detection labels only)\n",
    "# ================================\n",
    "# Official Downloads:\n",
    "# Images: https://bdd-data.berkeley.edu/\n",
    "# Labels: https://bdd-data.berkeley.edu/\n",
    "\n",
    "!wget http://128.32.162.150/bdd100k/bdd100k_images_100k.zip -O {ROOT}/bdd100k_images.zip\n",
    "!wget http://128.32.162.150/bdd100k/bdd100k_labels.zip -O {ROOT}/bdd100k_labels.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgCW2djXhp2G",
    "outputId": "25c7807f-e814-4015-ecfc-af7321c6eb00"
   },
   "outputs": [],
   "source": [
    "# Extract everything\n",
    "\n",
    "# Folder Structure After Extraction:\n",
    "# ROOT/bdd100k/images/100k/{train,val}\n",
    "# ROOT/bdd100k/labels/det_20/{train,val}.json\n",
    "\n",
    "print(\"Extracting images ...\")\n",
    "!unzip -q {ROOT}/bdd100k_images.zip -d {ROOT}/images_100k\n",
    "\n",
    "print(\"Extracting labels ...\")\n",
    "!unzip -q {ROOT}/bdd100k_labels.zip -d {ROOT}/labels_100k\n",
    "\n",
    "print(\"Extraction Complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2Hpigy4K5Oe"
   },
   "outputs": [],
   "source": [
    "# debugging to check annotations are written in labels\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "\n",
    "classes = {\n",
    "    \"person\": 0, \"rider\": 1, \"car\": 2, \"bus\": 3, \"truck\": 4,\n",
    "    \"bike\": 5, \"motorcycle\": 6, \"traffic light\": 7,\n",
    "    \"traffic sign\": 8, \"train\": 9\n",
    "}\n",
    "json_path = f\"/content/BDD100K_YOLO/labels/train/0000f77c-6257be58.json\"\n",
    "with open(json_path, 'r') as jf:\n",
    "  ann = json.load(jf)\n",
    "  #shutil.copy(img_path, f\"{out_img_dir}/{img_name}\")\n",
    "\n",
    "# Height/width fallback\n",
    "  h = ann.get(\"height\", 720)\n",
    "  w = ann.get(\"width\", 1280)\n",
    "\n",
    "# Open output label file\n",
    "  out_lbl_path = f\"/content/BDD100K_YOLO/0000f77c-6257be58.txt\"\n",
    "  with open(out_lbl_path, \"w\") as out_f:\n",
    "\n",
    "    frame_objects = ann.get(\"frames\", [{}])[0].get(\"objects\", [])\n",
    "\n",
    "    # Loop through annotations\n",
    "    for obj in frame_objects:\n",
    "        cls_name = obj.get(\"category\")\n",
    "\n",
    "        # Skip unknown classes\n",
    "        if cls_name not in classes:\n",
    "            continue\n",
    "\n",
    "        # Bounding box\n",
    "        box = obj.get(\"box2d\", None)\n",
    "        if not box:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = box[\"x1\"], box[\"y1\"], box[\"x2\"], box[\"y2\"]\n",
    "\n",
    "        # Convert to YOLO format\n",
    "        xc = (x1 + x2) / 2 / w\n",
    "        yc = (y1 + y2) / 2 / h\n",
    "        bw = (x2 - x1) / w\n",
    "        bh = (y2 - y1) / h\n",
    "\n",
    "        out_f.write(f\"{classes[cls_name]} {xc} {yc} {bw} {bh}\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTJPew1XI1Dx",
    "outputId": "f704173d-b348-4c4a-eb9d-0d65450daf5d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_split(split, IMG_DIR, JSON_DIR, OUT_DIR, classes):\n",
    "    \"\"\"\n",
    "    Convert per-image JSON annotations to YOLO TXT format.\n",
    "\n",
    "    Args:\n",
    "        split (str): \"train\", \"val\", or \"test\"\n",
    "        IMG_DIR (str): path to image directory containing JPGs\n",
    "        JSON_DIR (str): path to directory containing JSON files (one per image)\n",
    "        OUT_DIR (str): output directory root to save YOLO images/labels\n",
    "        classes (dict): category‚Üíindex mapping\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\nüîÑ Converting split: {split}\")\n",
    "\n",
    "    # Make output directories\n",
    "    out_img_dir = f\"{OUT_DIR}/{split}/images\"\n",
    "    out_lbl_dir = f\"{OUT_DIR}/{split}/labels\"\n",
    "    os.makedirs(out_img_dir, exist_ok=True)\n",
    "    os.makedirs(out_lbl_dir, exist_ok=True)\n",
    "\n",
    "    # Get all images for this split\n",
    "    image_list = sorted([f for f in os.listdir(f\"{IMG_DIR}/{split}\") if f.endswith('.jpg')])\n",
    "\n",
    "    for img_name in tqdm(image_list):\n",
    "\n",
    "        img_path = f\"{IMG_DIR}/{split}/{img_name}\"\n",
    "\n",
    "        # EXPECT JSON NAMED SAME AS IMAGE (e.g., 00001.jpg ‚Üí 00001.json)\n",
    "        json_name = img_name.replace(\".jpg\", \".json\")\n",
    "        json_path = f\"{JSON_DIR}/{split}/{json_name}\"\n",
    "\n",
    "        # Check if JSON exists\n",
    "        if not os.path.exists(json_path):\n",
    "            print(f\"‚ö†Ô∏è Missing annotation: {json_path} (skipping)\")\n",
    "            continue\n",
    "\n",
    "        # Load annotation JSON\n",
    "        with open(json_path, 'r') as jf:\n",
    "            ann = json.load(jf)\n",
    "\n",
    "        # Copy image to YOLO dataset\n",
    "        shutil.copy(img_path, f\"{out_img_dir}/{img_name}\")\n",
    "\n",
    "        # Height/width fallback\n",
    "        h = ann.get(\"height\", 720)\n",
    "        w = ann.get(\"width\", 1280)\n",
    "\n",
    "        # Open output label file\n",
    "        out_lbl_path = f\"{out_lbl_dir}/{img_name.replace('.jpg', '.txt')}\"\n",
    "        with open(out_lbl_path, \"w\") as out_f:\n",
    "\n",
    "            frame_objects = ann.get(\"frames\", [{}])[0].get(\"objects\", [])\n",
    "            # Loop through annotations\n",
    "            for obj in frame_objects:\n",
    "                cls_name = obj.get(\"category\")\n",
    "\n",
    "                # Skip unknown classes\n",
    "                if cls_name not in classes:\n",
    "                    continue\n",
    "\n",
    "                # Bounding box\n",
    "                box = obj.get(\"box2d\", None)\n",
    "                if not box:\n",
    "                    continue\n",
    "\n",
    "                x1, y1, x2, y2 = box[\"x1\"], box[\"y1\"], box[\"x2\"], box[\"y2\"]\n",
    "\n",
    "                # Convert to YOLO format\n",
    "                xc = (x1 + x2) / 2 / w\n",
    "                yc = (y1 + y2) / 2 / h\n",
    "                bw = (x2 - x1) / w\n",
    "                bh = (y2 - y1) / h\n",
    "\n",
    "                out_f.write(f\"{classes[cls_name]} {xc} {yc} {bw} {bh}\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Completed {split}\")\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Example Usage\n",
    "# ========================\n",
    "\n",
    "classes = {\n",
    "    \"person\": 0, \"rider\": 1, \"car\": 2, \"bus\": 3, \"truck\": 4,\n",
    "    \"bike\": 5, \"motorcycle\": 6, \"traffic light\": 7,\n",
    "    \"traffic sign\": 8, \"train\": 9\n",
    "}\n",
    "\n",
    "IMG_DIR = \"/content/BDD100K_YOLO/images_100k\"           # contains train/, val/, test/\n",
    "JSON_DIR = \"/content/BDD100K_YOLO/labels_100k\"     # contains train/, val/, test/\n",
    "OUT_DIR = \"/content/BDD100K_YOLO/dataset\"\n",
    "\n",
    "convert_split(\"train\", IMG_DIR, JSON_DIR, OUT_DIR, classes)\n",
    "convert_split(\"val\", IMG_DIR, JSON_DIR, OUT_DIR, classes)\n",
    "convert_split(\"test\", IMG_DIR, JSON_DIR, OUT_DIR, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVoCABHriEG9",
    "outputId": "16cfd7a4-7bc1-4ab4-bf90-4b7c7568528e"
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5. Create YAML File for Training\n",
    "# ================================\n",
    "yaml_path = f\"{ROOT}/bdd100k.yaml\"\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    f.write(f\"\"\"\n",
    "path: {ROOT}/dataset\n",
    "\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "names:\n",
    "  0: person\n",
    "  1: rider\n",
    "  2: car\n",
    "  3: bus\n",
    "  4: truck\n",
    "  5: bike\n",
    "  6: motorcycle\n",
    "  7: traffic light\n",
    "  8: traffic sign\n",
    "  9: train\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "print(\"bdd100k.yaml created!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cVonUuuHjGZO",
    "outputId": "8be08b51-c5f0-4f32-abb7-7630f1f068a8"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os, json, shutil, zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===========================================\n",
    "# 1) Train YOLOv11 + Save Fine-Tuned Model\n",
    "# ===========================================\n",
    "\n",
    "save_dir = \"yolo11n_bdd100k\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    imgsz=640,\n",
    "    epochs=5,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    workers=2,\n",
    "    project=\"yolo11m_bdd100k\",        # save training logs here\n",
    "    name=\"train_run\",\n",
    "    save=True,\n",
    "    save_period=1            # save checkpoint every epoch\n",
    ")\n",
    "\n",
    "print(\"‚úî Training Completed!\")\n",
    "print(f\"‚úî Saved fine-tuned weights at: {save_dir}/train_run/weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fa5aABTijZg8"
   },
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 1) Save fine-tuned YOLO model\n",
    "# ===========================================\n",
    "\n",
    "model_path = \"/content/BDD100K_YOLO/yolo_finetuned_bdd100k.pt\"\n",
    "model.save(model_path)\n",
    "print(f\"‚úî Fine-tuned model saved at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07fsNhRKf8eZ",
    "outputId": "bdb3072b-93b7-4a1e-87c2-35a9e6c26fbb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===========================================\n",
    "# 2) Generate Validation Performance Metrics\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\nüìä Generating Evaluation Metrics...\")\n",
    "\n",
    "metrics = model.val()    # runs validation & returns DetMetrics object\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# 3) Write metrics to a readable text file\n",
    "# ===========================================\n",
    "\n",
    "metrics_path = f\"{save_dir}/metrics_summary.txt\"\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "\n",
    "    f.write(\"===== YOLO Validation Metrics =====\\n\\n\")\n",
    "    f.write(f\"mAP@50:       {metrics.box.map50:.4f}\\n\")\n",
    "    f.write(f\"mAP@50-95:    {metrics.box.map:.4f}\\n\")\n",
    "    f.write(f\"Precision:    {metrics.box.mp:.4f}\\n\")\n",
    "    f.write(f\"Recall:       {metrics.box.mr:.4f}\\n\\n\")\n",
    "\n",
    "    # per-class AP if available\n",
    "    if hasattr(metrics.box, \"ap_class_index\"):\n",
    "        f.write(\"===== Per-Class AP =====\\n\")\n",
    "        for cls_idx, ap in zip(metrics.box.ap_class_index, metrics.box.ap):\n",
    "            f.write(f\"class {cls_idx}: AP = {ap:.4f}\\n\")\n",
    "\n",
    "print(\"‚úî Metrics written to:\", metrics_path)\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# 4) Print summary metrics to notebook output\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n===== VAL METRICS =====\")\n",
    "print(f\"mAP50:     {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95:  {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall:    {metrics.box.mr:.4f}\")\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# 5) Save Confusion Matrix Image\n",
    "# ===========================================\n",
    "\n",
    "if hasattr(metrics, \"confusion_matrix\") and metrics.confusion_matrix is not None:\n",
    "    metrics.confusion_matrix.plot(\n",
    "        normalize=True,\n",
    "        save_dir=save_dir\n",
    "    )\n",
    "    print(f\"‚úî Confusion matrix saved in {save_dir}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö† No confusion matrix found (possibly empty dataset or configuration).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "UpghusVaDfbU",
    "outputId": "082e3d3c-ca55-4883-b4f6-9ca2376104a5"
   },
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 3) Plot Train/Val Loss & Accuracy Curves\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\nüìâ Generating Training Curves...\")\n",
    "\n",
    "csv_path = f\"{save_dir}/train_run/results.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(df['epoch'], df['train/box_loss'], label='Train Box Loss')\n",
    "plt.plot(df['epoch'], df['train/cls_loss'], label='Train Cls Loss')\n",
    "plt.plot(df['epoch'], df['val/box_loss'], label='Val Box Loss')\n",
    "plt.plot(df['epoch'], df['val/cls_loss'], label='Val Cls Loss')\n",
    "\n",
    "plt.title(\"YOLOv11 Loss Curves\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{save_dir}/loss_curves.png\")\n",
    "plt.show()\n",
    "\n",
    "# Accuracy metrics plot (Precision, Recall, mAP)\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(df['epoch'], df['metrics/precision(B)'], label=\"Precision\")\n",
    "plt.plot(df['epoch'], df['metrics/recall(B)'], label=\"Recall\")\n",
    "plt.plot(df['epoch'], df['metrics/mAP50(B)'], label=\"mAP50\")\n",
    "plt.plot(df['epoch'], df['metrics/mAP50-95(B)'], label=\"mAP50-95\")\n",
    "\n",
    "plt.title(\"YOLOv11 Accuracy Metrics Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{save_dir}/metric_curves.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úî Training curves saved in:\", save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y3v9efEUDsk7",
    "outputId": "53ae3ffa-aa11-426e-c7df-6e3105f1b98e"
   },
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 4) Run Inference on Test Dataset\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\nüîç Running Inference on TEST Images...\")\n",
    "\n",
    "test_results_dir = \"/content/BDD100K_YOLO/test_preds\"\n",
    "os.makedirs(test_results_dir, exist_ok=True)\n",
    "\n",
    "preds = model.predict(\n",
    "    source=f\"{ROOT}/dataset/test/images\",\n",
    "    imgsz=640,\n",
    "    save=True,\n",
    "    project=test_results_dir,\n",
    "    name=\"preds\",\n",
    "    conf=0.25\n",
    ")\n",
    "\n",
    "print(\"‚úî Inference Completed!\")\n",
    "print(\"‚úî Output saved at:\", test_results_dir + \"/preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zc1WWhB5Imjr",
    "outputId": "5735342b-bbbd-4971-d1e1-8c6f3b880d7d"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: Display a few predictions\n",
    "import glob\n",
    "from IPython.display import Image\n",
    "\n",
    "pred_imgs = glob.glob(test_results_dir + \"/preds/*.jpg\")[:5]\n",
    "for img in pred_imgs:\n",
    "    display(Image(filename=img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "id": "IMhkM8rfuQai",
    "outputId": "ea75c26e-3e9d-4b9a-e438-86ba3cdcfe9c"
   },
   "outputs": [],
   "source": [
    "# export the model in ONNX format for inference\n",
    "\n",
    "model.export(\n",
    "    format=\"onnx\",\n",
    "    opset=12,          # ‚ú® REQUIRED for OpenCV\n",
    "    simplify=True,\n",
    "    dynamic=False       # recommended\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
